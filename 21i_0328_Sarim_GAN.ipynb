{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 7 - GAN Implementation\n",
        "## Name: Sarim Aeyzaz\n",
        "## Roll No: i21-0328\n"
      ],
      "metadata": {
        "id": "TG1cn6hAgWmn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AczRCzbE5HG",
        "outputId": "bfe003ad-2716-4b83-ae5e-9183e9334a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.1.0+cu118\n",
            "CUDA version: 11.8\n",
            "\n",
            "Random Seed:  1\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.datasets as dset\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "CUDA = True     # Change to False for CPU training\n",
        "DATA_PATH = '~/Data/mnist'\n",
        "BATCH_SIZE = 2048\n",
        "IMAGE_CHANNEL = 1\n",
        "X_DIM, Z_DIM = 64, 100\n",
        "G_HIDDEN, D_HIDDEN = 64, 64\n",
        "REAL_LABEL, FAKE_LABEL = 1, 0\n",
        "EPOCH_NUM = 12\n",
        "FAKE_LABEL = 0\n",
        "lr = 2e-4\n",
        "seed = 1            # Change to None to get different results at each run\n",
        "\n",
        "CUDA = CUDA and torch.cuda.is_available()\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if CUDA:\n",
        "    print(f\"CUDA version: {torch.version.cuda}\\n\")\n",
        "\n",
        "if seed is None:\n",
        "    seed = np.random.randint(1, 10000)\n",
        "print(\"Random Seed: \", seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if CUDA:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "cudnn.benchmark = True      # May train faster but cost more memory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dset.MNIST(root=DATA_PATH, download=True,\n",
        "                      transform=transforms.Compose([\n",
        "                      transforms.Resize(X_DIM),\n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize((0.5,), (0.5,))\n",
        "                      ]))\n",
        "\n",
        "assert dataset\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")"
      ],
      "metadata": {
        "id": "931TxiKSimW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    \"\"\"custom weights initialization\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # 1st layer\n",
        "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN * 8),\n",
        "            nn.ReLU(True),\n",
        "            # 2nd layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN * 4),\n",
        "            nn.ReLU(True),\n",
        "            # 3rd layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN * 2),\n",
        "            nn.ReLU(True),\n",
        "            # 4th layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(G_HIDDEN),\n",
        "            nn.ReLU(True),\n",
        "            # output layer\n",
        "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # 1st layer\n",
        "            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 2nd layer\n",
        "            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(D_HIDDEN * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 3rd layer\n",
        "            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(D_HIDDEN * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # 4th layer\n",
        "            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(D_HIDDEN * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # output layer\n",
        "            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1).squeeze(1)"
      ],
      "metadata": {
        "id": "piDays0TCw9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(optimizerD, x_real, real_label):\n",
        "      optimizerD.zero_grad()\n",
        "\n",
        "      # Update D with real data\n",
        "      read_predictions = netD(x_real).to(device)\n",
        "      real_loss = criterion(read_predictions, real_label)\n",
        "\n",
        "      # Fake Images\n",
        "      z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
        "      fake_images = netG(z_noise).to(device)\n",
        "\n",
        "      # Update D with fake data\n",
        "      fake_predictions = netD(fake_images).to(device)\n",
        "      fake_loss = criterion(fake_predictions, fake_label)\n",
        "\n",
        "      loss = real_loss + fake_loss\n",
        "      loss.backward()\n",
        "      optimizerD.step()\n",
        "\n",
        "      return real_loss.item(), fake_loss.item()"
      ],
      "metadata": {
        "id": "3-DkO0s3LbQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator(optimizerG, real_label):\n",
        "    optimizerG.zero_grad()\n",
        "\n",
        "    # Fake Images\n",
        "    z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
        "    fake_images = netG(z_noise).to(device)\n",
        "\n",
        "    # Update G with fake data\n",
        "    fake_predictions = netD(fake_images).to(device)\n",
        "    loss = criterion(fake_predictions, real_label)\n",
        "    loss.backward()\n",
        "    optimizerG.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "vpPtrjgOMBI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InvDsqnOXemC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c1c833-38e2-4ed1-8853-e8e91d9b90d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "netG = Generator().to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)\n",
        "\n",
        "netD = Discriminator().to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: I've increased batch size from 512 to 2048 in order make it run a bit faster on my system\n",
        "\n",
        "for epoch in range(EPOCH_NUM):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        x_real = data[0].to(device)\n",
        "\n",
        "        real_label = torch.full((x_real.size(0),), REAL_LABEL, device=device, dtype=torch.float32)\n",
        "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL, device=device, dtype=torch.float32)\n",
        "\n",
        "        real, fake = train_discriminator(optimizerD, x_real, real_label)\n",
        "        loss = train_generator(optimizerG, real_label)\n",
        "\n",
        "        print(f'Epoch {epoch} [{i}/{len(dataloader)}] Loss D (Real): {real: .4f} Loss D (Fake): {fake: .4f} Loss G: {loss: .4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6t547cTZzeD",
        "outputId": "9eeb975a-4355-4ab9-aa01-af8a633ae241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 [0/30] Loss D (Real):  1.1149 Loss D (Fake):  1.0050 Loss G:  2.4114\n",
            "Epoch 0 [1/30] Loss D (Real):  0.0022 Loss D (Fake):  3.0609 Loss G:  3.3350\n",
            "Epoch 0 [2/30] Loss D (Real):  0.0049 Loss D (Fake):  1.7216 Loss G:  5.7054\n",
            "Epoch 0 [3/30] Loss D (Real):  0.0553 Loss D (Fake):  0.5069 Loss G:  6.7337\n",
            "Epoch 0 [4/30] Loss D (Real):  0.1690 Loss D (Fake):  0.2512 Loss G:  6.2437\n",
            "Epoch 0 [5/30] Loss D (Real):  0.1993 Loss D (Fake):  0.3869 Loss G:  6.7481\n",
            "Epoch 0 [6/30] Loss D (Real):  0.1561 Loss D (Fake):  0.2109 Loss G:  7.2319\n",
            "Epoch 0 [7/30] Loss D (Real):  0.0834 Loss D (Fake):  0.1574 Loss G:  7.3065\n",
            "Epoch 0 [8/30] Loss D (Real):  0.0478 Loss D (Fake):  0.1302 Loss G:  7.4557\n",
            "Epoch 0 [9/30] Loss D (Real):  0.0473 Loss D (Fake):  0.1278 Loss G:  7.7582\n",
            "Epoch 0 [10/30] Loss D (Real):  0.0543 Loss D (Fake):  0.1178 Loss G:  8.1559\n",
            "Epoch 0 [11/30] Loss D (Real):  0.0560 Loss D (Fake):  0.0960 Loss G:  8.0973\n",
            "Epoch 0 [12/30] Loss D (Real):  0.0549 Loss D (Fake):  0.1337 Loss G:  9.1571\n",
            "Epoch 0 [13/30] Loss D (Real):  0.0665 Loss D (Fake):  0.0552 Loss G:  8.1975\n",
            "Epoch 0 [14/30] Loss D (Real):  0.0416 Loss D (Fake):  0.1866 Loss G:  11.3774\n",
            "Epoch 0 [15/30] Loss D (Real):  0.0893 Loss D (Fake):  0.0078 Loss G:  9.0827\n",
            "Epoch 0 [16/30] Loss D (Real):  0.0278 Loss D (Fake):  0.1920 Loss G:  12.2053\n",
            "Epoch 0 [17/30] Loss D (Real):  0.0628 Loss D (Fake):  0.0063 Loss G:  9.8317\n",
            "Epoch 0 [18/30] Loss D (Real):  0.0341 Loss D (Fake):  0.0994 Loss G:  9.9736\n",
            "Epoch 0 [19/30] Loss D (Real):  0.0475 Loss D (Fake):  0.0447 Loss G:  9.2864\n",
            "Epoch 0 [20/30] Loss D (Real):  0.0521 Loss D (Fake):  0.1102 Loss G:  11.9696\n",
            "Epoch 0 [21/30] Loss D (Real):  0.0999 Loss D (Fake):  0.0066 Loss G:  8.1500\n",
            "Epoch 0 [22/30] Loss D (Real):  0.0129 Loss D (Fake):  0.2634 Loss G:  17.9688\n",
            "Epoch 0 [23/30] Loss D (Real):  0.2800 Loss D (Fake):  0.0000 Loss G:  15.5347\n",
            "Epoch 0 [24/30] Loss D (Real):  0.0067 Loss D (Fake):  0.0005 Loss G:  8.6542\n",
            "Epoch 0 [25/30] Loss D (Real):  0.0011 Loss D (Fake):  0.5576 Loss G:  22.1099\n",
            "Epoch 0 [26/30] Loss D (Real):  0.1093 Loss D (Fake):  0.0000 Loss G:  23.6780\n",
            "Epoch 0 [27/30] Loss D (Real):  0.1366 Loss D (Fake):  0.0000 Loss G:  16.7797\n",
            "Epoch 0 [28/30] Loss D (Real):  0.0151 Loss D (Fake):  0.0015 Loss G:  7.0785\n",
            "Epoch 0 [29/30] Loss D (Real):  0.0037 Loss D (Fake):  1.4190 Loss G:  26.3401\n",
            "Epoch 1 [0/30] Loss D (Real):  0.6549 Loss D (Fake):  0.0000 Loss G:  28.7702\n",
            "Epoch 1 [1/30] Loss D (Real):  0.0076 Loss D (Fake):  0.0000 Loss G:  26.4774\n",
            "Epoch 1 [2/30] Loss D (Real):  0.0030 Loss D (Fake):  0.0000 Loss G:  17.5492\n",
            "Epoch 1 [3/30] Loss D (Real):  0.0016 Loss D (Fake):  0.0094 Loss G:  5.6092\n",
            "Epoch 1 [4/30] Loss D (Real):  0.0007 Loss D (Fake):  4.6176 Loss G:  27.7614\n",
            "Epoch 1 [5/30] Loss D (Real):  0.5926 Loss D (Fake):  0.0000 Loss G:  32.2690\n",
            "Epoch 1 [6/30] Loss D (Real):  0.1427 Loss D (Fake):  0.0000 Loss G:  33.3786\n",
            "Epoch 1 [7/30] Loss D (Real):  0.0537 Loss D (Fake):  0.0000 Loss G:  33.6332\n",
            "Epoch 1 [8/30] Loss D (Real):  0.0203 Loss D (Fake):  0.0000 Loss G:  33.5516\n",
            "Epoch 1 [9/30] Loss D (Real):  0.0123 Loss D (Fake):  0.0000 Loss G:  33.3947\n",
            "Epoch 1 [10/30] Loss D (Real):  0.0083 Loss D (Fake):  0.0000 Loss G:  33.1682\n",
            "Epoch 1 [11/30] Loss D (Real):  0.0069 Loss D (Fake):  0.0000 Loss G:  32.8848\n",
            "Epoch 1 [12/30] Loss D (Real):  0.0045 Loss D (Fake):  0.0000 Loss G:  32.4979\n",
            "Epoch 1 [13/30] Loss D (Real):  0.0034 Loss D (Fake):  0.0000 Loss G:  31.9712\n",
            "Epoch 1 [14/30] Loss D (Real):  0.0058 Loss D (Fake):  0.0000 Loss G:  31.1622\n",
            "Epoch 1 [15/30] Loss D (Real):  0.0063 Loss D (Fake):  0.0000 Loss G:  29.6517\n",
            "Epoch 1 [16/30] Loss D (Real):  0.0021 Loss D (Fake):  0.0000 Loss G:  26.1303\n",
            "Epoch 1 [17/30] Loss D (Real):  0.0023 Loss D (Fake):  0.0000 Loss G:  16.4116\n",
            "Epoch 1 [18/30] Loss D (Real):  0.0020 Loss D (Fake):  0.0265 Loss G:  6.1997\n",
            "Epoch 1 [19/30] Loss D (Real):  0.0025 Loss D (Fake):  4.1146 Loss G:  32.5071\n",
            "Epoch 1 [20/30] Loss D (Real):  7.7975 Loss D (Fake):  0.0000 Loss G:  31.2633\n",
            "Epoch 1 [21/30] Loss D (Real):  0.0475 Loss D (Fake):  0.0000 Loss G:  29.2917\n",
            "Epoch 1 [22/30] Loss D (Real):  0.0338 Loss D (Fake):  0.0000 Loss G:  24.4756\n",
            "Epoch 1 [23/30] Loss D (Real):  0.0288 Loss D (Fake):  0.0000 Loss G:  11.2391\n",
            "Epoch 1 [24/30] Loss D (Real):  0.0189 Loss D (Fake):  2.4314 Loss G:  27.0140\n",
            "Epoch 1 [25/30] Loss D (Real):  2.5982 Loss D (Fake):  0.0000 Loss G:  24.9762\n",
            "Epoch 1 [26/30] Loss D (Real):  0.2062 Loss D (Fake):  0.0000 Loss G:  15.8936\n",
            "Epoch 1 [27/30] Loss D (Real):  0.0659 Loss D (Fake):  0.3014 Loss G:  11.3267\n",
            "Epoch 1 [28/30] Loss D (Real):  0.0844 Loss D (Fake):  0.5808 Loss G:  21.0137\n",
            "Epoch 1 [29/30] Loss D (Real):  1.2013 Loss D (Fake):  0.0000 Loss G:  15.9908\n",
            "Epoch 2 [0/30] Loss D (Real):  0.1825 Loss D (Fake):  0.0025 Loss G:  6.0334\n",
            "Epoch 2 [1/30] Loss D (Real):  0.0299 Loss D (Fake):  3.5354 Loss G:  28.2867\n",
            "Epoch 2 [2/30] Loss D (Real):  2.8981 Loss D (Fake):  0.0000 Loss G:  28.1066\n",
            "Epoch 2 [3/30] Loss D (Real):  0.1105 Loss D (Fake):  0.0000 Loss G:  25.1984\n",
            "Epoch 2 [4/30] Loss D (Real):  0.0385 Loss D (Fake):  0.0000 Loss G:  17.3107\n",
            "Epoch 2 [5/30] Loss D (Real):  0.0209 Loss D (Fake):  0.0389 Loss G:  6.6247\n",
            "Epoch 2 [6/30] Loss D (Real):  0.0088 Loss D (Fake):  4.1969 Loss G:  23.5750\n",
            "Epoch 2 [7/30] Loss D (Real):  0.9615 Loss D (Fake):  0.0000 Loss G:  23.5119\n",
            "Epoch 2 [8/30] Loss D (Real):  0.5502 Loss D (Fake):  0.0000 Loss G:  14.8608\n",
            "Epoch 2 [9/30] Loss D (Real):  0.0737 Loss D (Fake):  0.0091 Loss G:  5.3799\n",
            "Epoch 2 [10/30] Loss D (Real):  0.0168 Loss D (Fake):  2.4390 Loss G:  20.5901\n",
            "Epoch 2 [11/30] Loss D (Real):  2.5449 Loss D (Fake):  0.0000 Loss G:  11.7881\n",
            "Epoch 2 [12/30] Loss D (Real):  0.0302 Loss D (Fake):  0.0379 Loss G:  2.8478\n",
            "Epoch 2 [13/30] Loss D (Real):  0.0058 Loss D (Fake):  2.3920 Loss G:  16.3158\n",
            "Epoch 2 [14/30] Loss D (Real):  1.2713 Loss D (Fake):  0.0000 Loss G:  13.2530\n",
            "Epoch 2 [15/30] Loss D (Real):  0.1738 Loss D (Fake):  0.0020 Loss G:  7.3438\n",
            "Epoch 2 [16/30] Loss D (Real):  0.0311 Loss D (Fake):  0.1778 Loss G:  4.5685\n",
            "Epoch 2 [17/30] Loss D (Real):  0.0230 Loss D (Fake):  0.6922 Loss G:  11.2143\n",
            "Epoch 2 [18/30] Loss D (Real):  0.8253 Loss D (Fake):  0.0014 Loss G:  6.9243\n",
            "Epoch 2 [19/30] Loss D (Real):  0.0699 Loss D (Fake):  0.0845 Loss G:  3.7197\n",
            "Epoch 2 [20/30] Loss D (Real):  0.0192 Loss D (Fake):  0.7931 Loss G:  11.5177\n",
            "Epoch 2 [21/30] Loss D (Real):  0.9191 Loss D (Fake):  0.0008 Loss G:  7.4288\n",
            "Epoch 2 [22/30] Loss D (Real):  0.0529 Loss D (Fake):  0.0327 Loss G:  3.7875\n",
            "Epoch 2 [23/30] Loss D (Real):  0.0190 Loss D (Fake):  0.4978 Loss G:  7.9555\n",
            "Epoch 2 [24/30] Loss D (Real):  0.1053 Loss D (Fake):  0.0072 Loss G:  7.9746\n",
            "Epoch 2 [25/30] Loss D (Real):  0.1655 Loss D (Fake):  0.0078 Loss G:  5.3618\n",
            "Epoch 2 [26/30] Loss D (Real):  0.0684 Loss D (Fake):  0.1264 Loss G:  4.7713\n",
            "Epoch 2 [27/30] Loss D (Real):  0.0745 Loss D (Fake):  0.1442 Loss G:  5.4233\n",
            "Epoch 2 [28/30] Loss D (Real):  0.1563 Loss D (Fake):  0.0796 Loss G:  4.6009\n",
            "Epoch 2 [29/30] Loss D (Real):  0.1322 Loss D (Fake):  0.1323 Loss G:  4.7077\n",
            "Epoch 3 [0/30] Loss D (Real):  0.1330 Loss D (Fake):  0.0911 Loss G:  4.4271\n",
            "Epoch 3 [1/30] Loss D (Real):  0.1155 Loss D (Fake):  0.1086 Loss G:  4.7858\n",
            "Epoch 3 [2/30] Loss D (Real):  0.1334 Loss D (Fake):  0.0740 Loss G:  4.3741\n",
            "Epoch 3 [3/30] Loss D (Real):  0.0919 Loss D (Fake):  0.1020 Loss G:  4.7708\n",
            "Epoch 3 [4/30] Loss D (Real):  0.1027 Loss D (Fake):  0.0613 Loss G:  4.4930\n",
            "Epoch 3 [5/30] Loss D (Real):  0.0978 Loss D (Fake):  0.0757 Loss G:  4.4408\n",
            "Epoch 3 [6/30] Loss D (Real):  0.0854 Loss D (Fake):  0.0756 Loss G:  4.7041\n",
            "Epoch 3 [7/30] Loss D (Real):  0.0841 Loss D (Fake):  0.0583 Loss G:  4.7807\n",
            "Epoch 3 [8/30] Loss D (Real):  0.0745 Loss D (Fake):  0.0479 Loss G:  4.4759\n",
            "Epoch 3 [10/30] Loss D (Real):  0.0782 Loss D (Fake):  0.0526 Loss G:  4.7410\n",
            "Epoch 3 [11/30] Loss D (Real):  0.0685 Loss D (Fake):  0.0447 Loss G:  4.6596\n",
            "Epoch 3 [12/30] Loss D (Real):  0.0661 Loss D (Fake):  0.0439 Loss G:  4.6042\n",
            "Epoch 3 [13/30] Loss D (Real):  0.0530 Loss D (Fake):  0.0517 Loss G:  5.0277\n",
            "Epoch 3 [14/30] Loss D (Real):  0.0616 Loss D (Fake):  0.0378 Loss G:  4.9254\n",
            "Epoch 3 [15/30] Loss D (Real):  0.0576 Loss D (Fake):  0.0533 Loss G:  4.9402\n",
            "Epoch 3 [16/30] Loss D (Real):  0.0696 Loss D (Fake):  0.0567 Loss G:  5.0136\n",
            "Epoch 3 [17/30] Loss D (Real):  0.0802 Loss D (Fake):  0.0649 Loss G:  5.2218\n",
            "Epoch 3 [18/30] Loss D (Real):  0.0954 Loss D (Fake):  0.0610 Loss G:  5.2702\n",
            "Epoch 3 [19/30] Loss D (Real):  0.0832 Loss D (Fake):  0.0642 Loss G:  5.6158\n",
            "Epoch 3 [20/30] Loss D (Real):  0.0740 Loss D (Fake):  0.0504 Loss G:  5.5729\n",
            "Epoch 3 [21/30] Loss D (Real):  0.0649 Loss D (Fake):  0.0567 Loss G:  5.6797\n",
            "Epoch 3 [22/30] Loss D (Real):  0.0780 Loss D (Fake):  0.0631 Loss G:  5.7209\n",
            "Epoch 3 [23/30] Loss D (Real):  0.0705 Loss D (Fake):  0.0814 Loss G:  6.6895\n",
            "Epoch 3 [24/30] Loss D (Real):  0.1095 Loss D (Fake):  0.0367 Loss G:  5.4697\n",
            "Epoch 3 [25/30] Loss D (Real):  0.0550 Loss D (Fake):  0.1472 Loss G:  9.3057\n",
            "Epoch 3 [26/30] Loss D (Real):  0.2039 Loss D (Fake):  0.0025 Loss G:  6.4359\n",
            "Epoch 3 [27/30] Loss D (Real):  0.0287 Loss D (Fake):  0.0373 Loss G:  4.8865\n",
            "Epoch 3 [28/30] Loss D (Real):  0.0112 Loss D (Fake):  0.1072 Loss G:  8.0211\n",
            "Epoch 3 [29/30] Loss D (Real):  0.0432 Loss D (Fake):  0.0033 Loss G:  8.1084\n",
            "Epoch 4 [0/30] Loss D (Real):  0.0437 Loss D (Fake):  0.0029 Loss G:  6.4577\n",
            "Epoch 4 [1/30] Loss D (Real):  0.0284 Loss D (Fake):  0.0150 Loss G:  4.8581\n",
            "Epoch 4 [2/30] Loss D (Real):  0.0194 Loss D (Fake):  0.0642 Loss G:  6.3581\n",
            "Epoch 4 [3/30] Loss D (Real):  0.0483 Loss D (Fake):  0.0142 Loss G:  6.0039\n",
            "Epoch 4 [4/30] Loss D (Real):  0.0474 Loss D (Fake):  0.0213 Loss G:  5.1177\n",
            "Epoch 4 [5/30] Loss D (Real):  0.0363 Loss D (Fake):  0.0643 Loss G:  6.5453\n",
            "Epoch 4 [6/30] Loss D (Real):  0.0655 Loss D (Fake):  0.0202 Loss G:  5.4980\n",
            "Epoch 4 [7/30] Loss D (Real):  0.0521 Loss D (Fake):  0.0745 Loss G:  6.6043\n",
            "Epoch 4 [8/30] Loss D (Real):  0.1048 Loss D (Fake):  0.0317 Loss G:  4.8728\n",
            "Epoch 4 [9/30] Loss D (Real):  0.0374 Loss D (Fake):  0.1253 Loss G:  8.9166\n",
            "Epoch 4 [10/30] Loss D (Real):  0.2795 Loss D (Fake):  0.0023 Loss G:  2.8256\n",
            "Epoch 4 [11/30] Loss D (Real):  0.0093 Loss D (Fake):  0.6591 Loss G:  20.9400\n",
            "Epoch 4 [12/30] Loss D (Real):  5.3405 Loss D (Fake):  0.0000 Loss G:  0.9998\n",
            "Epoch 4 [13/30] Loss D (Real):  0.0018 Loss D (Fake):  3.1405 Loss G:  16.9091\n",
            "Epoch 4 [14/30] Loss D (Real):  4.9871 Loss D (Fake):  0.0001 Loss G:  5.1178\n",
            "Epoch 4 [15/30] Loss D (Real):  0.0567 Loss D (Fake):  0.9041 Loss G:  4.4357\n",
            "Epoch 4 [16/30] Loss D (Real):  0.1498 Loss D (Fake):  0.5924 Loss G:  7.4615\n",
            "Epoch 4 [17/30] Loss D (Real):  1.0079 Loss D (Fake):  0.0262 Loss G:  3.5417\n",
            "Epoch 4 [18/30] Loss D (Real):  0.1750 Loss D (Fake):  0.7717 Loss G:  6.4135\n",
            "Epoch 4 [19/30] Loss D (Real):  0.6062 Loss D (Fake):  0.0723 Loss G:  4.1169\n",
            "Epoch 4 [20/30] Loss D (Real):  0.1586 Loss D (Fake):  0.4016 Loss G:  5.5329\n",
            "Epoch 4 [21/30] Loss D (Real):  0.2369 Loss D (Fake):  0.0726 Loss G:  4.9539\n",
            "Epoch 4 [22/30] Loss D (Real):  0.1190 Loss D (Fake):  0.1357 Loss G:  4.5557\n",
            "Epoch 4 [23/30] Loss D (Real):  0.1044 Loss D (Fake):  0.2295 Loss G:  5.6887\n",
            "Epoch 4 [24/30] Loss D (Real):  0.2579 Loss D (Fake):  0.0722 Loss G:  3.8643\n",
            "Epoch 4 [25/30] Loss D (Real):  0.1183 Loss D (Fake):  0.1971 Loss G:  4.1892\n",
            "Epoch 4 [26/30] Loss D (Real):  0.1726 Loss D (Fake):  0.1079 Loss G:  3.9481\n",
            "Epoch 4 [27/30] Loss D (Real):  0.1384 Loss D (Fake):  0.1169 Loss G:  3.9529\n",
            "Epoch 4 [28/30] Loss D (Real):  0.1145 Loss D (Fake):  0.1074 Loss G:  4.1179\n",
            "Epoch 4 [29/30] Loss D (Real):  0.1017 Loss D (Fake):  0.0937 Loss G:  4.2276\n",
            "Epoch 5 [0/30] Loss D (Real):  0.1230 Loss D (Fake):  0.0791 Loss G:  3.9039\n",
            "Epoch 5 [1/30] Loss D (Real):  0.0972 Loss D (Fake):  0.1110 Loss G:  4.1463\n",
            "Epoch 5 [2/30] Loss D (Real):  0.1041 Loss D (Fake):  0.0957 Loss G:  4.1658\n",
            "Epoch 5 [3/30] Loss D (Real):  0.1043 Loss D (Fake):  0.1163 Loss G:  4.2771\n",
            "Epoch 5 [4/30] Loss D (Real):  0.1318 Loss D (Fake):  0.1907 Loss G:  4.9413\n",
            "Epoch 5 [5/30] Loss D (Real):  0.2776 Loss D (Fake):  0.1597 Loss G:  3.9844\n",
            "Epoch 5 [6/30] Loss D (Real):  0.2312 Loss D (Fake):  0.3454 Loss G:  6.8667\n",
            "Epoch 5 [7/30] Loss D (Real):  0.4326 Loss D (Fake):  0.0149 Loss G:  3.6273\n",
            "Epoch 5 [8/30] Loss D (Real):  0.0390 Loss D (Fake):  0.3482 Loss G:  7.8328\n",
            "Epoch 5 [9/30] Loss D (Real):  0.1784 Loss D (Fake):  0.0096 Loss G:  6.5950\n",
            "Epoch 5 [10/30] Loss D (Real):  0.0900 Loss D (Fake):  0.0487 Loss G:  4.1279\n",
            "Epoch 5 [11/30] Loss D (Real):  0.0537 Loss D (Fake):  0.3306 Loss G:  6.5475\n",
            "Epoch 5 [12/30] Loss D (Real):  0.3610 Loss D (Fake):  0.0408 Loss G:  3.4866\n",
            "Epoch 5 [13/30] Loss D (Real):  0.0943 Loss D (Fake):  0.3913 Loss G:  5.8357\n",
            "Epoch 5 [14/30] Loss D (Real):  0.4900 Loss D (Fake):  0.0294 Loss G:  2.0617\n",
            "Epoch 5 [15/30] Loss D (Real):  0.0275 Loss D (Fake):  0.5508 Loss G:  7.3919\n",
            "Epoch 5 [16/30] Loss D (Real):  0.5547 Loss D (Fake):  0.0042 Loss G:  3.9349\n",
            "Epoch 5 [17/30] Loss D (Real):  0.0382 Loss D (Fake):  0.1256 Loss G:  3.2065\n",
            "Epoch 5 [18/30] Loss D (Real):  0.0225 Loss D (Fake):  0.2281 Loss G:  5.3144\n",
            "Epoch 5 [19/30] Loss D (Real):  0.1301 Loss D (Fake):  0.0480 Loss G:  4.8483\n",
            "Epoch 5 [20/30] Loss D (Real):  0.1380 Loss D (Fake):  0.0849 Loss G:  3.3576\n",
            "Epoch 5 [21/30] Loss D (Real):  0.1096 Loss D (Fake):  0.2587 Loss G:  4.6638\n",
            "Epoch 5 [22/30] Loss D (Real):  0.2961 Loss D (Fake):  0.0694 Loss G:  2.7353\n",
            "Epoch 5 [23/30] Loss D (Real):  0.0719 Loss D (Fake):  0.3091 Loss G:  5.4306\n",
            "Epoch 5 [24/30] Loss D (Real):  0.3776 Loss D (Fake):  0.0251 Loss G:  2.1990\n",
            "Epoch 5 [25/30] Loss D (Real):  0.0301 Loss D (Fake):  0.3874 Loss G:  5.7894\n",
            "Epoch 5 [26/30] Loss D (Real):  0.2711 Loss D (Fake):  0.0137 Loss G:  3.9847\n",
            "Epoch 5 [27/30] Loss D (Real):  0.0640 Loss D (Fake):  0.0767 Loss G:  3.1179\n",
            "Epoch 5 [28/30] Loss D (Real):  0.0409 Loss D (Fake):  0.1528 Loss G:  4.5395\n",
            "Epoch 5 [29/30] Loss D (Real):  0.1570 Loss D (Fake):  0.0446 Loss G:  3.5470\n",
            "Epoch 6 [0/30] Loss D (Real):  0.0839 Loss D (Fake):  0.1012 Loss G:  3.5573\n",
            "Epoch 6 [1/30] Loss D (Real):  0.0881 Loss D (Fake):  0.1105 Loss G:  4.1080\n",
            "Epoch 6 [2/30] Loss D (Real):  0.1355 Loss D (Fake):  0.0523 Loss G:  3.2122\n",
            "Epoch 6 [3/30] Loss D (Real):  0.0766 Loss D (Fake):  0.1300 Loss G:  4.1500\n",
            "Epoch 6 [4/30] Loss D (Real):  0.1212 Loss D (Fake):  0.0501 Loss G:  3.5510\n",
            "Epoch 6 [5/30] Loss D (Real):  0.0696 Loss D (Fake):  0.0849 Loss G:  3.8507\n",
            "Epoch 6 [6/30] Loss D (Real):  0.0750 Loss D (Fake):  0.0675 Loss G:  4.0393\n",
            "Epoch 6 [7/30] Loss D (Real):  0.0805 Loss D (Fake):  0.0611 Loss G:  3.7438\n",
            "Epoch 6 [8/30] Loss D (Real):  0.0770 Loss D (Fake):  0.0791 Loss G:  3.8335\n",
            "Epoch 6 [9/30] Loss D (Real):  0.0870 Loss D (Fake):  0.0774 Loss G:  3.8391\n",
            "Epoch 6 [10/30] Loss D (Real):  0.1019 Loss D (Fake):  0.0865 Loss G:  3.7464\n",
            "Epoch 6 [11/30] Loss D (Real):  0.1025 Loss D (Fake):  0.0927 Loss G:  3.7157\n",
            "Epoch 6 [12/30] Loss D (Real):  0.0914 Loss D (Fake):  0.0904 Loss G:  3.9895\n",
            "Epoch 6 [13/30] Loss D (Real):  0.0994 Loss D (Fake):  0.0699 Loss G:  3.7488\n",
            "Epoch 6 [14/30] Loss D (Real):  0.0718 Loss D (Fake):  0.0925 Loss G:  4.4389\n",
            "Epoch 6 [15/30] Loss D (Real):  0.0953 Loss D (Fake):  0.0475 Loss G:  3.6447\n",
            "Epoch 6 [16/30] Loss D (Real):  0.0427 Loss D (Fake):  0.0845 Loss G:  4.4863\n",
            "Epoch 6 [17/30] Loss D (Real):  0.0770 Loss D (Fake):  0.0381 Loss G:  3.9417\n",
            "Epoch 6 [18/30] Loss D (Real):  0.0544 Loss D (Fake):  0.0669 Loss G:  4.0286\n",
            "Epoch 6 [19/30] Loss D (Real):  0.0550 Loss D (Fake):  0.0626 Loss G:  4.1103\n",
            "Epoch 6 [20/30] Loss D (Real):  0.0667 Loss D (Fake):  0.0648 Loss G:  3.8757\n",
            "Epoch 6 [21/30] Loss D (Real):  0.0767 Loss D (Fake):  0.0859 Loss G:  3.8254\n",
            "Epoch 6 [22/30] Loss D (Real):  0.0816 Loss D (Fake):  0.0891 Loss G:  3.8339\n",
            "Epoch 6 [23/30] Loss D (Real):  0.0891 Loss D (Fake):  0.0855 Loss G:  3.8321\n",
            "Epoch 6 [24/30] Loss D (Real):  0.0919 Loss D (Fake):  0.0952 Loss G:  3.7712\n",
            "Epoch 6 [25/30] Loss D (Real):  0.0889 Loss D (Fake):  0.0921 Loss G:  3.7630\n",
            "Epoch 6 [26/30] Loss D (Real):  0.0846 Loss D (Fake):  0.0839 Loss G:  3.7650\n",
            "Epoch 6 [27/30] Loss D (Real):  0.0933 Loss D (Fake):  0.0930 Loss G:  3.7756\n",
            "Epoch 6 [28/30] Loss D (Real):  0.0987 Loss D (Fake):  0.0911 Loss G:  3.8229\n",
            "Epoch 6 [29/30] Loss D (Real):  0.0808 Loss D (Fake):  0.0630 Loss G:  3.5988\n",
            "Epoch 7 [0/30] Loss D (Real):  0.0608 Loss D (Fake):  0.0875 Loss G:  4.4517\n",
            "Epoch 7 [1/30] Loss D (Real):  0.1062 Loss D (Fake):  0.0399 Loss G:  3.1545\n",
            "Epoch 7 [2/30] Loss D (Real):  0.0237 Loss D (Fake):  0.1351 Loss G:  5.8083\n",
            "Epoch 7 [3/30] Loss D (Real):  0.2087 Loss D (Fake):  0.0113 Loss G:  1.8607\n",
            "Epoch 7 [4/30] Loss D (Real):  0.0084 Loss D (Fake):  0.4641 Loss G:  10.4111\n",
            "Epoch 7 [5/30] Loss D (Real):  2.2938 Loss D (Fake):  0.0002 Loss G:  0.0024\n",
            "Epoch 7 [6/30] Loss D (Real):  0.0000 Loss D (Fake):  7.0546 Loss G:  8.5851\n",
            "Epoch 7 [7/30] Loss D (Real):  2.3060 Loss D (Fake):  0.0042 Loss G:  1.8466\n",
            "Epoch 7 [8/30] Loss D (Real):  0.0220 Loss D (Fake):  1.5322 Loss G:  5.1474\n",
            "Epoch 7 [9/30] Loss D (Real):  0.7291 Loss D (Fake):  0.1938 Loss G:  2.8928\n",
            "Epoch 7 [10/30] Loss D (Real):  0.3517 Loss D (Fake):  0.7605 Loss G:  5.1996\n",
            "Epoch 7 [11/30] Loss D (Real):  1.2875 Loss D (Fake):  0.0477 Loss G:  0.5786\n",
            "Epoch 7 [12/30] Loss D (Real):  0.0184 Loss D (Fake):  1.8291 Loss G:  10.5391\n",
            "Epoch 7 [13/30] Loss D (Real):  1.5663 Loss D (Fake):  0.0011 Loss G:  6.4936\n",
            "Epoch 7 [14/30] Loss D (Real):  0.1449 Loss D (Fake):  0.1954 Loss G:  2.5061\n",
            "Epoch 7 [15/30] Loss D (Real):  0.0446 Loss D (Fake):  1.5247 Loss G:  9.7877\n",
            "Epoch 7 [16/30] Loss D (Real):  2.0373 Loss D (Fake):  0.0012 Loss G:  5.2526\n",
            "Epoch 7 [17/30] Loss D (Real):  0.1873 Loss D (Fake):  0.1665 Loss G:  2.4016\n",
            "Epoch 7 [18/30] Loss D (Real):  0.0327 Loss D (Fake):  1.1149 Loss G:  7.9637\n",
            "Epoch 7 [19/30] Loss D (Real):  1.0468 Loss D (Fake):  0.0124 Loss G:  3.8718\n",
            "Epoch 7 [20/30] Loss D (Real):  0.1073 Loss D (Fake):  0.4054 Loss G:  3.9860\n",
            "Epoch 7 [21/30] Loss D (Real):  0.1242 Loss D (Fake):  0.3013 Loss G:  5.5856\n",
            "Epoch 7 [22/30] Loss D (Real):  0.4081 Loss D (Fake):  0.0647 Loss G:  3.3556\n",
            "Epoch 7 [23/30] Loss D (Real):  0.1396 Loss D (Fake):  0.3712 Loss G:  5.4449\n",
            "Epoch 7 [24/30] Loss D (Real):  0.3625 Loss D (Fake):  0.0262 Loss G:  4.0740\n",
            "Epoch 7 [25/30] Loss D (Real):  0.0769 Loss D (Fake):  0.0762 Loss G:  3.6717\n",
            "Epoch 7 [26/30] Loss D (Real):  0.0419 Loss D (Fake):  0.1296 Loss G:  4.7825\n",
            "Epoch 7 [27/30] Loss D (Real):  0.0704 Loss D (Fake):  0.0486 Loss G:  4.7744\n",
            "Epoch 7 [28/30] Loss D (Real):  0.0844 Loss D (Fake):  0.0767 Loss G:  4.2397\n",
            "Epoch 7 [29/30] Loss D (Real):  0.1153 Loss D (Fake):  0.1236 Loss G:  3.9388\n",
            "Epoch 8 [0/30] Loss D (Real):  0.1268 Loss D (Fake):  0.1405 Loss G:  3.9491\n",
            "Epoch 8 [1/30] Loss D (Real):  0.1829 Loss D (Fake):  0.1174 Loss G:  3.2835\n",
            "Epoch 8 [2/30] Loss D (Real):  0.1258 Loss D (Fake):  0.1678 Loss G:  3.8098\n",
            "Epoch 8 [3/30] Loss D (Real):  0.1780 Loss D (Fake):  0.0886 Loss G:  3.1565\n",
            "Epoch 8 [4/30] Loss D (Real):  0.0805 Loss D (Fake):  0.1331 Loss G:  3.8417\n",
            "Epoch 8 [5/30] Loss D (Real):  0.0964 Loss D (Fake):  0.0614 Loss G:  3.8651\n",
            "Epoch 8 [6/30] Loss D (Real):  0.0723 Loss D (Fake):  0.0628 Loss G:  3.6773\n",
            "Epoch 8 [7/30] Loss D (Real):  0.0590 Loss D (Fake):  0.0675 Loss G:  3.8057\n",
            "Epoch 8 [8/30] Loss D (Real):  0.0526 Loss D (Fake):  0.0660 Loss G:  3.9733\n",
            "Epoch 8 [9/30] Loss D (Real):  0.0740 Loss D (Fake):  0.0528 Loss G:  3.5880\n",
            "Epoch 8 [10/30] Loss D (Real):  0.0573 Loss D (Fake):  0.0877 Loss G:  3.7600\n",
            "Epoch 8 [11/30] Loss D (Real):  0.0753 Loss D (Fake):  0.0813 Loss G:  3.7219\n",
            "Epoch 8 [12/30] Loss D (Real):  0.0980 Loss D (Fake):  0.0770 Loss G:  3.2493\n",
            "Epoch 8 [13/30] Loss D (Real):  0.0834 Loss D (Fake):  0.1089 Loss G:  3.3529\n",
            "Epoch 8 [14/30] Loss D (Real):  0.0958 Loss D (Fake):  0.0889 Loss G:  3.3860\n",
            "Epoch 8 [15/30] Loss D (Real):  0.1010 Loss D (Fake):  0.0722 Loss G:  2.9709\n",
            "Epoch 8 [16/30] Loss D (Real):  0.0716 Loss D (Fake):  0.1063 Loss G:  3.4091\n",
            "Epoch 8 [17/30] Loss D (Real):  0.0961 Loss D (Fake):  0.0746 Loss G:  3.2637\n",
            "Epoch 8 [18/30] Loss D (Real):  0.0923 Loss D (Fake):  0.0796 Loss G:  3.0492\n",
            "Epoch 8 [19/30] Loss D (Real):  0.0678 Loss D (Fake):  0.1059 Loss G:  3.7509\n",
            "Epoch 8 [20/30] Loss D (Real):  0.1203 Loss D (Fake):  0.0539 Loss G:  2.8486\n",
            "Epoch 8 [21/30] Loss D (Real):  0.0539 Loss D (Fake):  0.1306 Loss G:  4.1359\n",
            "Epoch 8 [22/30] Loss D (Real):  0.1369 Loss D (Fake):  0.0387 Loss G:  2.8745\n",
            "Epoch 8 [23/30] Loss D (Real):  0.0389 Loss D (Fake):  0.1205 Loss G:  4.1462\n",
            "Epoch 8 [24/30] Loss D (Real):  0.1090 Loss D (Fake):  0.0371 Loss G:  3.2422\n",
            "Epoch 8 [25/30] Loss D (Real):  0.0502 Loss D (Fake):  0.0875 Loss G:  3.8140\n",
            "Epoch 8 [26/30] Loss D (Real):  0.0824 Loss D (Fake):  0.0484 Loss G:  3.3556\n",
            "Epoch 8 [27/30] Loss D (Real):  0.0584 Loss D (Fake):  0.0778 Loss G:  3.7146\n",
            "Epoch 8 [28/30] Loss D (Real):  0.0761 Loss D (Fake):  0.0595 Loss G:  3.3941\n",
            "Epoch 8 [29/30] Loss D (Real):  0.0673 Loss D (Fake):  0.0762 Loss G:  3.4850\n",
            "Epoch 9 [0/30] Loss D (Real):  0.0800 Loss D (Fake):  0.0685 Loss G:  3.4023\n",
            "Epoch 9 [1/30] Loss D (Real):  0.0701 Loss D (Fake):  0.0886 Loss G:  3.7627\n",
            "Epoch 9 [2/30] Loss D (Real):  0.0925 Loss D (Fake):  0.0658 Loss G:  3.1792\n",
            "Epoch 9 [3/30] Loss D (Real):  0.0625 Loss D (Fake):  0.1108 Loss G:  4.0385\n",
            "Epoch 9 [4/30] Loss D (Real):  0.1488 Loss D (Fake):  0.0558 Loss G:  2.3560\n",
            "Epoch 9 [5/30] Loss D (Real):  0.0300 Loss D (Fake):  0.2528 Loss G:  6.3281\n",
            "Epoch 9 [6/30] Loss D (Real):  0.6441 Loss D (Fake):  0.0071 Loss G:  0.1592\n",
            "Epoch 9 [7/30] Loss D (Real):  0.0008 Loss D (Fake):  2.4760 Loss G:  16.7093\n",
            "Epoch 9 [8/30] Loss D (Real):  8.5664 Loss D (Fake):  0.0000 Loss G:  9.2896\n",
            "Epoch 9 [9/30] Loss D (Real):  2.4411 Loss D (Fake):  0.0015 Loss G:  0.0173\n",
            "Epoch 9 [10/30] Loss D (Real):  0.0001 Loss D (Fake):  5.8237 Loss G:  1.7652\n",
            "Epoch 9 [11/30] Loss D (Real):  0.0267 Loss D (Fake):  0.9121 Loss G:  7.9754\n",
            "Epoch 9 [12/30] Loss D (Real):  2.6153 Loss D (Fake):  0.0062 Loss G:  2.4526\n",
            "Epoch 9 [13/30] Loss D (Real):  0.3069 Loss D (Fake):  0.7919 Loss G:  1.8208\n",
            "Epoch 9 [14/30] Loss D (Real):  0.2852 Loss D (Fake):  0.8350 Loss G:  4.8201\n",
            "Epoch 9 [15/30] Loss D (Real):  1.4011 Loss D (Fake):  0.0378 Loss G:  1.5949\n",
            "Epoch 9 [16/30] Loss D (Real):  0.1345 Loss D (Fake):  0.7751 Loss G:  4.2633\n",
            "Epoch 9 [17/30] Loss D (Real):  0.3971 Loss D (Fake):  0.0746 Loss G:  3.6660\n",
            "Epoch 9 [18/30] Loss D (Real):  0.2493 Loss D (Fake):  0.1697 Loss G:  2.9298\n",
            "Epoch 9 [19/30] Loss D (Real):  0.1442 Loss D (Fake):  0.3836 Loss G:  4.7470\n",
            "Epoch 9 [20/30] Loss D (Real):  0.4112 Loss D (Fake):  0.0883 Loss G:  3.3025\n",
            "Epoch 9 [21/30] Loss D (Real):  0.2215 Loss D (Fake):  0.3509 Loss G:  3.7477\n",
            "Epoch 9 [22/30] Loss D (Real):  0.3161 Loss D (Fake):  0.2236 Loss G:  3.6641\n",
            "Epoch 9 [23/30] Loss D (Real):  0.3251 Loss D (Fake):  0.1800 Loss G:  3.1207\n",
            "Epoch 9 [24/30] Loss D (Real):  0.1731 Loss D (Fake):  0.2144 Loss G:  4.2487\n",
            "Epoch 9 [25/30] Loss D (Real):  0.1673 Loss D (Fake):  0.0962 Loss G:  4.1078\n",
            "Epoch 9 [26/30] Loss D (Real):  0.1133 Loss D (Fake):  0.1949 Loss G:  4.5514\n",
            "Epoch 9 [27/30] Loss D (Real):  0.1617 Loss D (Fake):  0.2387 Loss G:  4.9079\n",
            "Epoch 9 [28/30] Loss D (Real):  0.3129 Loss D (Fake):  0.1665 Loss G:  3.6288\n",
            "Epoch 9 [29/30] Loss D (Real):  0.1985 Loss D (Fake):  0.2914 Loss G:  4.9365\n",
            "Epoch 10 [0/30] Loss D (Real):  0.2649 Loss D (Fake):  0.0522 Loss G:  3.7662\n",
            "Epoch 10 [1/30] Loss D (Real):  0.0771 Loss D (Fake):  0.1264 Loss G:  4.0451\n",
            "Epoch 10 [2/30] Loss D (Real):  0.0741 Loss D (Fake):  0.1288 Loss G:  4.6674\n",
            "Epoch 10 [3/30] Loss D (Real):  0.0962 Loss D (Fake):  0.1042 Loss G:  4.4721\n",
            "Epoch 10 [4/30] Loss D (Real):  0.1617 Loss D (Fake):  0.2242 Loss G:  4.4133\n",
            "Epoch 10 [5/30] Loss D (Real):  0.2749 Loss D (Fake):  0.1720 Loss G:  3.3288\n",
            "Epoch 10 [6/30] Loss D (Real):  0.2515 Loss D (Fake):  0.2038 Loss G:  3.3346\n",
            "Epoch 10 [7/30] Loss D (Real):  0.1896 Loss D (Fake):  0.1283 Loss G:  3.4822\n",
            "Epoch 10 [8/30] Loss D (Real):  0.1067 Loss D (Fake):  0.1248 Loss G:  4.0429\n",
            "Epoch 10 [9/30] Loss D (Real):  0.1186 Loss D (Fake):  0.0928 Loss G:  3.7453\n",
            "Epoch 10 [10/30] Loss D (Real):  0.0990 Loss D (Fake):  0.1711 Loss G:  4.3003\n",
            "Epoch 10 [11/30] Loss D (Real):  0.2062 Loss D (Fake):  0.1218 Loss G:  3.0147\n",
            "Epoch 10 [12/30] Loss D (Real):  0.1258 Loss D (Fake):  0.2991 Loss G:  4.6036\n",
            "Epoch 10 [13/30] Loss D (Real):  0.5062 Loss D (Fake):  0.0501 Loss G:  0.9114\n",
            "Epoch 10 [14/30] Loss D (Real):  0.0147 Loss D (Fake):  1.0578 Loss G:  7.8788\n",
            "Epoch 10 [15/30] Loss D (Real):  1.6211 Loss D (Fake):  0.0029 Loss G:  1.5951\n",
            "Epoch 10 [16/30] Loss D (Real):  0.0075 Loss D (Fake):  0.6601 Loss G:  3.4076\n",
            "Epoch 10 [17/30] Loss D (Real):  0.0306 Loss D (Fake):  0.1815 Loss G:  4.9913\n",
            "Epoch 10 [18/30] Loss D (Real):  0.2028 Loss D (Fake):  0.0527 Loss G:  3.8233\n",
            "Epoch 10 [19/30] Loss D (Real):  0.1593 Loss D (Fake):  0.1439 Loss G:  2.7649\n",
            "Epoch 10 [20/30] Loss D (Real):  0.1191 Loss D (Fake):  0.2571 Loss G:  3.5123\n",
            "Epoch 10 [21/30] Loss D (Real):  0.2542 Loss D (Fake):  0.0955 Loss G:  2.6996\n",
            "Epoch 10 [22/30] Loss D (Real):  0.1041 Loss D (Fake):  0.1712 Loss G:  3.1785\n",
            "Epoch 10 [23/30] Loss D (Real):  0.1217 Loss D (Fake):  0.1158 Loss G:  3.3411\n",
            "Epoch 10 [24/30] Loss D (Real):  0.1181 Loss D (Fake):  0.0975 Loss G:  3.2238\n",
            "Epoch 10 [25/30] Loss D (Real):  0.1010 Loss D (Fake):  0.1048 Loss G:  3.1896\n",
            "Epoch 10 [26/30] Loss D (Real):  0.0995 Loss D (Fake):  0.0996 Loss G:  3.1879\n",
            "Epoch 10 [27/30] Loss D (Real):  0.0957 Loss D (Fake):  0.0921 Loss G:  3.0694\n",
            "Epoch 10 [28/30] Loss D (Real):  0.0885 Loss D (Fake):  0.1052 Loss G:  3.2865\n",
            "Epoch 10 [29/30] Loss D (Real):  0.0909 Loss D (Fake):  0.0774 Loss G:  3.1537\n",
            "Epoch 11 [0/30] Loss D (Real):  0.1012 Loss D (Fake):  0.0946 Loss G:  2.9799\n",
            "Epoch 11 [1/30] Loss D (Real):  0.0883 Loss D (Fake):  0.1037 Loss G:  3.1190\n",
            "Epoch 11 [2/30] Loss D (Real):  0.0908 Loss D (Fake):  0.0965 Loss G:  3.1825\n",
            "Epoch 11 [3/30] Loss D (Real):  0.1069 Loss D (Fake):  0.0894 Loss G:  2.9789\n",
            "Epoch 11 [4/30] Loss D (Real):  0.0856 Loss D (Fake):  0.1140 Loss G:  3.1752\n",
            "Epoch 11 [5/30] Loss D (Real):  0.0975 Loss D (Fake):  0.0884 Loss G:  3.0411\n",
            "Epoch 11 [6/30] Loss D (Real):  0.0939 Loss D (Fake):  0.0980 Loss G:  3.0707\n",
            "Epoch 11 [7/30] Loss D (Real):  0.0908 Loss D (Fake):  0.1104 Loss G:  3.1804\n",
            "Epoch 11 [8/30] Loss D (Real):  0.1270 Loss D (Fake):  0.0891 Loss G:  2.8083\n",
            "Epoch 11 [9/30] Loss D (Real):  0.0692 Loss D (Fake):  0.1287 Loss G:  3.3261\n",
            "Epoch 11 [10/30] Loss D (Real):  0.1359 Loss D (Fake):  0.0778 Loss G:  2.7352\n",
            "Epoch 11 [11/30] Loss D (Real):  0.0667 Loss D (Fake):  0.1404 Loss G:  3.3580\n",
            "Epoch 11 [12/30] Loss D (Real):  0.1133 Loss D (Fake):  0.0754 Loss G:  2.9723\n",
            "Epoch 11 [13/30] Loss D (Real):  0.0789 Loss D (Fake):  0.1038 Loss G:  3.1094\n",
            "Epoch 11 [14/30] Loss D (Real):  0.0912 Loss D (Fake):  0.0950 Loss G:  3.2132\n",
            "Epoch 11 [15/30] Loss D (Real):  0.1030 Loss D (Fake):  0.0954 Loss G:  2.9145\n",
            "Epoch 11 [16/30] Loss D (Real):  0.0763 Loss D (Fake):  0.1206 Loss G:  3.4084\n",
            "Epoch 11 [17/30] Loss D (Real):  0.1154 Loss D (Fake):  0.0711 Loss G:  2.8754\n",
            "Epoch 11 [18/30] Loss D (Real):  0.0739 Loss D (Fake):  0.1211 Loss G:  3.2089\n",
            "Epoch 11 [19/30] Loss D (Real):  0.1082 Loss D (Fake):  0.0872 Loss G:  2.9383\n",
            "Epoch 11 [20/30] Loss D (Real):  0.0868 Loss D (Fake):  0.1090 Loss G:  3.0601\n",
            "Epoch 11 [21/30] Loss D (Real):  0.1155 Loss D (Fake):  0.0999 Loss G:  2.9565\n",
            "Epoch 11 [22/30] Loss D (Real):  0.0927 Loss D (Fake):  0.1294 Loss G:  3.3252\n",
            "Epoch 11 [23/30] Loss D (Real):  0.1301 Loss D (Fake):  0.0772 Loss G:  2.5215\n",
            "Epoch 11 [24/30] Loss D (Real):  0.0764 Loss D (Fake):  0.1673 Loss G:  3.8751\n",
            "Epoch 11 [25/30] Loss D (Real):  0.1792 Loss D (Fake):  0.0474 Loss G:  2.0604\n",
            "Epoch 11 [26/30] Loss D (Real):  0.0330 Loss D (Fake):  0.2401 Loss G:  4.9176\n",
            "Epoch 11 [27/30] Loss D (Real):  0.3444 Loss D (Fake):  0.0161 Loss G:  1.2060\n",
            "Epoch 11 [28/30] Loss D (Real):  0.0087 Loss D (Fake):  0.5651 Loss G:  7.2730\n",
            "Epoch 11 [29/30] Loss D (Real):  0.9163 Loss D (Fake):  0.0022 Loss G:  0.7509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWFCBwq5ewP_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}